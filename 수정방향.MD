로컬에서 카프카 , 레디스 , MYSQL 을 도커로 띄울 수 있게 만들어줘

현재 도커 컴포즈는 아래와 같아

services:

kafka:

image: apache/kafka:latest

container_name: ecommerce-api-kafka

hostname: kafka

ports:

- "9092:9092" # 외부(내 PC) 접속용

environment:

# [1] 서버 역할 및 식별

KAFKA_NODE_ID: 1

# 실무: 각 서버마다 유니크한 ID(1, 2, 3...) 부여



KAFKA_PROCESS_ROLES: broker,controller

# 실무: 대규모 환경에선 broker(데이터)와 controller(관리) 서버를 분리하기도 함



KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093

# 실무: 1@node1:9093,2@node2:9093,3@node3:9093 처럼 홀수 개의 관리자 리스트 지정



# [2] 통로(Listener) 설정

KAFKA_LISTENERS: INTERNAL://:29092,EXTERNAL://:9092,CONTROLLER://:9093

KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092

# 실무: EXTERNAL 주소에 'localhost' 대신 실제 서버의 '도메인'이나 '공인 IP' 입력



KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT

# 실무: 보안을 위해 PLAINTEXT 대신 SSL 또는 SASL_SSL(암호화/인증) 사용 필수

KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL



# [3] 데이터 복제 및 안전성 (가장 중요한 차이)

KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

# 실무: 3 (서버 1~2대가 죽어도 읽기/쓰기 위치 정보를 안전하게 보관)



KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

# 실무: 3 (트랜잭션 로그의 복제본 개수)



KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

# 실무: 2 (최소 2개 이상의 서버에 복제 성공 메시지가 와야 데이터 확정)



# [4] 성능 및 데이터 보관

KAFKA_NUM_PARTITIONS: 3

# 실무: 트래픽에 따라 10~50개 이상으로 설정 (병렬 처리 능력 결정)



KAFKA_LOG_RETENTION_HOURS: 168

# 실무: 저장소 용량에 따라 조절 (예: 24시간만 보관하거나 100GB 넘으면 삭제 등)



KAFKA_LOG_SEGMENT_BYTES: 1073741824 # 로그 한 파일당 크기 (1GB)

KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000 # 오래된 데이터 삭제 체크 주기



volumes:

- kafka-data:/var/lib/kafka/data

networks:

- ecommerce-network



kafka-ui:

image: provectuslabs/kafka-ui:latest

container_name: ecommerce-api-kafka-ui

ports:

- "8090:8080"

environment:

KAFKA_CLUSTERS_0_NAME: local

KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092

DYNAMIC_CONFIG_ENABLED: 'true'

depends_on:

- kafka

networks:

- ecommerce-network



networks:

ecommerce-network:

driver: bridge



volumes:

kafka-data:





# 볼륨 삭제

# docker-compose down -v



# docker-compose up -d





# my-test 토픽의 이전 메시지도 전부 줘

# docker exec -it kafka kafka-console-consumer --topic my-test --bootstrap-server kafka:9092 --from-beginning



# 1. my-test 토픽 생성 (내부 포트 29092 사용)

# docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-topics.sh --create --topic my-test --bootstrap-server localhost:29092



# 2. 메시지 생성 (Producer)

# docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-console-producer.sh --topic my-test --bootstrap-server localhost:29092



# 3. 메시지 구독 (Consumer) - 처음부터 다 가져오기

# docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-console-consumer.sh --topic my-test --bootstrap-server localhost:29092 --from-beginning



수정할 부분 있으면 수정하고...

"



MYSQL은 별도의 SCHEMA.SQL을 통해서 기본 테이블 구성 및 DML로 기본 데이터 인서트도 하도록 하고



또한 K6 , 인플럭스 DB , 그라파나 연동해서 부하테스트 할거야 해당 설정도 모두 추가해줘 ..





또한 현재의 스프링 코드가 추후 너가 만들어준 도커 설정 외에도 개발환경에 들어갔을때 여러 인프라 환경에 맞춰서 변경하기 쉽도록 만들어줘

사용자의 요청에 맞춰 MySQL(초기화 스크립트 포함), Redis, Kafka(기존 설정 유지), 그리고 부하 테스트를 위한 K6 + InfluxDB + Grafana 스택을 포함한 전체 docker-compose.yml을 작성했습니다.

또한, Spring Boot 애플리케이션이 다양한 인프라 환경(로컬, 개발, 운영 등)에서 유연하게 변경될 수 있도록 설정 파일(application.yml) 구성 전략도 함께 제안합니다.

1. 프로젝트 폴더 구조 (권장)
   도커 설정 파일과 초기화 스크립트를 깔끔하게 관리하기 위해 아래와 같은 폴더 구조를 추천합니다.

Plaintext
project-root/
├── docker-compose.yml
├── database/
│    └── init/
│         ├── 01-schema.sql  (테이블 생성)
│         └── 02-data.sql    (더미 데이터)
├── grafana/
│    └── provisioning/
│         └── datasources/
│              └── datasource.yml (그라파나-인플럭스DB 자동연결 설정)
└── k6/
└── scripts/
└── load-test.js
2. Docker Compose 통합 설정 (docker-compose.yml)
   아래 내용을 복사하여 사용하세요. 기존 Kafka 설정에 MySQL, Redis, 모니터링 스택을 통합했습니다.

YAML
version: '3.8'

services:
# ----------------------------------------
# 1. Message Broker (Kafka + UI)
# ----------------------------------------
kafka:
image: apache/kafka:latest
container_name: ecommerce-api-kafka
hostname: kafka
ports:
- "9092:9092"
environment:
KAFKA_NODE_ID: 1
KAFKA_PROCESS_ROLES: broker,controller
KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
KAFKA_LISTENERS: INTERNAL://:29092,EXTERNAL://:9092,CONTROLLER://:9093
KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
KAFKA_NUM_PARTITIONS: 3
KAFKA_LOG_RETENTION_HOURS: 168
volumes:
- kafka-data:/var/lib/kafka/data
networks:
- ecommerce-network

kafka-ui:
image: provectuslabs/kafka-ui:latest
container_name: ecommerce-api-kafka-ui
ports:
- "8090:8080"
environment:
KAFKA_CLUSTERS_0_NAME: local
KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
DYNAMIC_CONFIG_ENABLED: 'true'
depends_on:
- kafka
networks:
- ecommerce-network

# ----------------------------------------
# 2. Database (MySQL + Redis)
# ----------------------------------------
mysql:
image: mysql:8.0
container_name: ecommerce-api-mysql
hostname: mysql
ports:
- "3306:3306"
environment:
MYSQL_ROOT_PASSWORD: root
MYSQL_DATABASE: ecommerce
MYSQL_USER: user
MYSQL_PASSWORD: password
TZ: Asia/Seoul
volumes:
- mysql-data:/var/lib/mysql
# 초기화 스크립트 자동 실행 (알파벳 순서로 실행됨)
- ./database/init:/docker-entrypoint-initdb.d
command:
- --character-set-server=utf8mb4
- --collation-server=utf8mb4_unicode_ci
networks:
- ecommerce-network

redis:
image: redis:latest
container_name: ecommerce-api-redis
hostname: redis
ports:
- "6379:6379"
networks:
- ecommerce-network

# ----------------------------------------
# 3. Load Testing Stack (K6 + InfluxDB + Grafana)
# ----------------------------------------
influxdb:
image: influxdb:1.8
container_name: ecommerce-api-influxdb
hostname: influxdb
ports:
- "8086:8086"
environment:
- INFLUXDB_DB=k6
networks:
- ecommerce-network

grafana:
image: grafana/grafana:latest
container_name: ecommerce-api-grafana
ports:
- "3000:3000"
environment:
- GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
- GF_AUTH_ANONYMOUS_ENABLED=true
- GF_SECURITY_ADMIN_PASSWORD=admin
volumes:
# 그라파나 시작 시 InfluxDB를 자동으로 Datasource로 등록
- ./grafana/provisioning:/etc/grafana/provisioning
depends_on:
- influxdb
networks:
- ecommerce-network

k6:
image: grafana/k6:latest
container_name: ecommerce-api-k6
networks:
- ecommerce-network
ports:
- "6565:6565"
environment:
- K6_OUT=influxdb=http://influxdb:8086/k6
volumes:
- ./k6/scripts:/scripts
# 컨테이너를 계속 띄워두고 필요할 때 exec로 실행하려면 아래 command 사용
# command: sleep infinity
# 혹은 docker-compose up 실행 시 바로 특정 스크립트를 돌리려면 아래 사용
command: run /scripts/load-test.js

networks:
ecommerce-network:
driver: bridge

volumes:
kafka-data:
mysql-data:
3. 추가 설정 파일 (필수)
   위 docker-compose.yml이 정상 작동하려면 아래 파일들을 생성해야 합니다.

A. MySQL 초기화 파일 (database/init/01-schema.sql)
SQL
-- 예시: 기본 테이블 생성
CREATE TABLE IF NOT EXISTS product (
id BIGINT AUTO_INCREMENT PRIMARY KEY,
name VARCHAR(255),
price DECIMAL(10, 2)
);

-- 예시: 초기 데이터 삽입
INSERT INTO product (name, price) VALUES ('Test Product 1', 10000);
INSERT INTO product (name, price) VALUES ('Test Product 2', 20000);
B. Grafana 데이터소스 자동 연결 (grafana/provisioning/datasources/datasource.yml)
이 파일을 만들어두면 그라파나 접속 시 수동으로 DB를 연결할 필요가 없습니다.

YAML
apiVersion: 1

datasources:
- name: InfluxDB
  type: influxdb
  access: proxy
  url: http://influxdb:8086
  database: k6
  isDefault: true
  C. K6 테스트 스크립트 예시 (k6/scripts/load-test.js)
  JavaScript
  import http from 'k6/http';
  import { check, sleep } from 'k6';

export const options = {
stages: [
{ duration: '30s', target: 20 }, // 30초 동안 유저 20명까지 증가
{ duration: '1m', target: 20 },  // 1분간 유지
{ duration: '10s', target: 0 },  // 10초 동안 종료
],
};

export default function () {
// host.docker.internal은 컨테이너 안에서 내 PC(로컬호스트)를 찾을 때 사용
const res = http.get('http://host.docker.internal:8080/api/health');
check(res, { 'status was 200': (r) => r.status == 200 });
sleep(1);
}
4. Spring Boot 설정 전략 (환경 유연성 확보)
   "개발 환경에 들어갔을 때 여러 인프라 환경에 맞춰서 변경하기 쉽도록" 하려면, application.yml에 하드코딩을 피하고 환경 변수 치환자를 사용해야 합니다.

src/main/resources/application.yml을 아래와 같이 작성하면, 로컬에서는 기본값(Default)을 쓰고, 배포 시에는 환경 변수만 주입하면 됩니다.

YAML
spring:
config:
activate:
on-profile: default # 로컬 개발 시 기본 적용

datasource:
# 환경변수 DB_URL이 있으면 그걸 쓰고, 없으면 로컬호스트 사용
url: ${DB_URL:jdbc:mysql://localhost:3306/ecommerce}
username: ${DB_USERNAME:user}
password: ${DB_PASSWORD:password}
driver-class-name: com.mysql.cj.jdbc.Driver

data:
redis:
host: ${REDIS_HOST:localhost}
port: ${REDIS_PORT:6379}

kafka:
bootstrap-servers: ${KAFKA_SERVERS:localhost:9092}
consumer:
group-id: ${KAFKA_GROUP_ID:ecommerce-group}
auto-offset-reset: earliest

# ---------------------------------------------------
# 운영(Production) 또는 개발(Dev) 환경 예시
# ---------------------------------------------------
# 실제 배포 시에는 jar 실행 시 --spring.profiles.active=prod 옵션을 주거나
# 시스템 환경변수에 DB_URL 등을 설정하면 됨.
핵심 포인트
${변수명:기본값} 패턴: 환경 변수가 주입되면 그 값을 쓰고, 없으면 : 뒤의 기본값(로컬 Docker 설정)을 사용합니다.

Spring Profile 분리: 만약 설정이 너무 많이 다르다면 application-dev.yml, application-prod.yml로 파일을 나누는 것이 좋지만, 위처럼 환경 변수 우선순위를 활용하는 것이 클라우드 네이티브(Docker/K8s) 환경에서 가장 권장되는 방식입니다.

5. 실행 및 테스트 방법
   전체 실행:

Bash
docker-compose up -d
접속 확인:

Kafka UI: http://localhost:8090

Grafana: http://localhost:3000 (ID: admin / PW: admin - 첫 로그인 시 변경)

MySQL: 로컬 DB 툴에서 localhost:3306 접속 (user/password)

K6 부하 테스트 실행: 스프링 서버를 띄운 상태에서 아래 명령어로 부하 테스트 수행 (결과는 Grafana에서 확인 가능).

Bash
docker-compose run --rm k6 run /scripts/load-test.js
혹시 K6 스크립트 작성법이나 그라파나 대시보드 세팅에 대해 더 구체적인 도움이 필요하신가요?