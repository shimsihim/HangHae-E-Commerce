services:
  kafka:
    image: apache/kafka:latest
    container_name: ecommerce-api-kafka
    hostname: kafka
    ports:
      - "9092:9092"   # 외부(내 PC) 접속용
    environment:
      # [1] 서버 역할 및 식별
      KAFKA_NODE_ID: 1
      # 실무: 각 서버마다 유니크한 ID(1, 2, 3...) 부여

      KAFKA_PROCESS_ROLES: broker,controller
      # 실무: 대규모 환경에선 broker(데이터)와 controller(관리) 서버를 분리하기도 함

      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@localhost:9093
      # 실무: 1@node1:9093,2@node2:9093,3@node3:9093 처럼 홀수 개의 관리자 리스트 지정

      # [2] 통로(Listener) 설정
      KAFKA_LISTENERS: INTERNAL://:29092,EXTERNAL://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      # 실무: EXTERNAL 주소에 'localhost' 대신 실제 서버의 '도메인'이나 '공인 IP' 입력

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      # 실무: 보안을 위해 PLAINTEXT 대신 SSL 또는 SASL_SSL(암호화/인증) 사용 필수
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # [3] 데이터 복제 및 안전성 (가장 중요한 차이)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # 실무: 3 (서버 1~2대가 죽어도 읽기/쓰기 위치 정보를 안전하게 보관)

      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # 실무: 3 (트랜잭션 로그의 복제본 개수)

      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      # 실무: 2 (최소 2개 이상의 서버에 복제 성공 메시지가 와야 데이터 확정)

      # [4] 성능 및 데이터 보관
      KAFKA_NUM_PARTITIONS: 3
      # 실무: 트래픽에 따라 10~50개 이상으로 설정 (병렬 처리 능력 결정)

      KAFKA_LOG_RETENTION_HOURS: 168
      # 실무: 저장소 용량에 따라 조절 (예: 24시간만 보관하거나 100GB 넘으면 삭제 등)

      KAFKA_LOG_SEGMENT_BYTES: 1073741824         # 로그 한 파일당 크기 (1GB)
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000 # 오래된 데이터 삭제 체크 주기

    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - ecommerce-network

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: ecommerce-api-kafka-ui
    ports:
      - "8090:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      DYNAMIC_CONFIG_ENABLED: 'true'
    depends_on:
      - kafka
    networks:
      - ecommerce-network

networks:
  ecommerce-network:
    driver: bridge

volumes:
  kafka-data:


# 볼륨 삭제
# docker-compose down -v

# docker-compose up -d


# my-test 토픽의 이전 메시지도 전부 줘
# docker exec -it kafka kafka-console-consumer --topic my-test --bootstrap-server kafka:9092 --from-beginning

# 1. my-test 토픽 생성 (내부 포트 29092 사용)
  #  docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-topics.sh --create --topic my-test --bootstrap-server localhost:29092

  # 2. 메시지 생성 (Producer)
#  docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-console-producer.sh --topic my-test --bootstrap-server localhost:29092

  # 3. 메시지 구독 (Consumer) - 처음부터 다 가져오기
#  docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-console-consumer.sh --topic my-test --bootstrap-server localhost:29092 --from-beginning