version: '3.8'

services:
  # ==========================================
  # 1. Message Broker (Kafka + UI)
  # ==========================================
  kafka:
    image: apache/kafka:latest
    container_name: ecommerce-api-kafka
    hostname: kafka
    ports:
      - "9092:9092"   # 외부(내 PC) 접속용
    environment:
      # [1] 서버 역할 및 식별
      KAFKA_NODE_ID: 1
      # 실무: 각 서버마다 유니크한 ID(1, 2, 3...) 부여

      KAFKA_PROCESS_ROLES: broker,controller
      # 실무: 대규모 환경에선 broker(데이터)와 controller(관리) 서버를 분리하기도 함

      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      # 변경: 1@localhost:9093 -> 1@kafka:9093 (도커 네트워크 내부에서 hostname 사용)
      # 실무: 1@node1:9093,2@node2:9093,3@node3:9093 처럼 홀수 개의 관리자 리스트 지정

      # [2] 통로(Listener) 설정
      KAFKA_LISTENERS: INTERNAL://:29092,EXTERNAL://:9092,CONTROLLER://:9093
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      # 실무: EXTERNAL 주소에 'localhost' 대신 실제 서버의 '도메인'이나 '공인 IP' 입력

      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT
      # 실무: 보안을 위해 PLAINTEXT 대신 SSL 또는 SASL_SSL(암호화/인증) 사용 필수
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      # [3] 데이터 복제 및 안전성 (가장 중요한 차이)
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      # 실무: 3 (서버 1~2대가 죽어도 읽기/쓰기 위치 정보를 안전하게 보관)

      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      # 실무: 3 (트랜잭션 로그의 복제본 개수)

      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      # 실무: 2 (최소 2개 이상의 서버에 복제 성공 메시지가 와야 데이터 확정)

      # [4] 성능 및 데이터 보관
      KAFKA_NUM_PARTITIONS: 3
      # 실무: 트래픽에 따라 10~50개 이상으로 설정 (병렬 처리 능력 결정)

      KAFKA_LOG_RETENTION_HOURS: 168
      # 실무: 저장소 용량에 따라 조절 (예: 24시간만 보관하거나 100GB 넘으면 삭제 등)

      KAFKA_LOG_SEGMENT_BYTES: 1073741824         # 로그 한 파일당 크기 (1GB)
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000 # 오래된 데이터 삭제 체크 주기

    volumes:
      - kafka-data:/var/lib/kafka/data  # Kafka 데이터 영구 저장
    networks:
      - ecommerce-network
    # [추가] 헬스체크: Kafka가 정상적으로 시작되었는지 확인
    # 다른 서비스들이 Kafka가 완전히 준비될 때까지 대기할 수 있게 함
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions --bootstrap-server localhost:9092 || exit 1"]
      interval: 10s      # 10초마다 체크
      timeout: 5s        # 5초 안에 응답 없으면 실패
      retries: 5         # 5번 실패하면 unhealthy 상태

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: ecommerce-api-kafka-ui
    ports:
      - "8090:8080"   # 브라우저에서 localhost:8090 접속
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      DYNAMIC_CONFIG_ENABLED: 'true'
    depends_on:
      kafka:
        condition: service_healthy  # [변경] Kafka가 healthy 상태일 때만 시작
    networks:
      - ecommerce-network

  # ==========================================
  # 2. Database (MySQL + Redis)
  # ==========================================
  mysql:
    image: mysql:8.0
    container_name: ecommerce-api-mysql
    hostname: mysql
    ports:
      - "3306:3306"   # 로컬에서 MySQL 클라이언트로 접속 가능
    environment:
      MYSQL_ROOT_PASSWORD: admin        # root 계정 비밀번호
      MYSQL_DATABASE: commerce          # 시작 시 자동 생성할 데이터베이스
      TZ: Asia/Seoul                    # 타임존 설정 (한국 시간)
    volumes:
      - mysql-data:/var/lib/mysql       # MySQL 데이터 영구 저장
      # [추가] 초기화 스크립트 자동 실행
      # ./database/init 폴더의 .sql 파일들이 알파벳 순서로 실행됨
      # 예: 01-schema.sql -> 02-data.sql
      - ./database/init:/docker-entrypoint-initdb.d
    command:
      - --character-set-server=utf8mb4           # 한글, 이모지 지원
      - --collation-server=utf8mb4_unicode_ci    # 정렬 규칙
      - --default-authentication-plugin=mysql_native_password  # [추가] 인증 방식 (호환성)
    networks:
      - ecommerce-network
    # [추가] 헬스체크: MySQL이 정상적으로 시작되었는지 확인
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-uroot", "-padmin"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine   # [변경] alpine 버전 (경량화)
    container_name: ecommerce-api-redis
    hostname: redis
    ports:
      - "6379:6379"
    networks:
      - ecommerce-network
    # [추가] 헬스체크: Redis가 정상적으로 응답하는지 확인
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]  # PONG 응답 확인
      interval: 10s
      timeout: 3s
      retries: 5

  # ==========================================
  # 3. Load Testing Stack (K6 + InfluxDB + Grafana)
  # ==========================================
  influxdb:
    # [추가] InfluxDB 1.8: K6 테스트 결과를 시계열로 저장하는 DB
    image: influxdb:1.8-alpine
    container_name: ecommerce-api-influxdb
    hostname: influxdb
    ports:
      - "8086:8086"   # InfluxDB API 포트
    environment:
      - INFLUXDB_DB=k6                    # k6 결과를 저장할 데이터베이스 이름
      - INFLUXDB_ADMIN_USER=admin         # 관리자 계정
      - INFLUXDB_ADMIN_PASSWORD=admin     # 관리자 비밀번호
    volumes:
      - influxdb-data:/var/lib/influxdb   # InfluxDB 데이터 영구 저장
    networks:
      - ecommerce-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8086/ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  grafana:
    # [추가] Grafana: InfluxDB에 저장된 K6 테스트 결과를 그래프로 시각화
    image: grafana/grafana:latest
    container_name: ecommerce-api-grafana
    ports:
      - "3000:3000"   # 브라우저에서 localhost:3000 접속
    environment:
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin   # 로그인 없이 접속 가능 (개발용)
      - GF_AUTH_ANONYMOUS_ENABLED=true     # 익명 접속 활성화
      - GF_SECURITY_ADMIN_PASSWORD=admin   # 관리자 비밀번호
      - GF_SECURITY_ADMIN_USER=admin       # 관리자 계정
    volumes:
      - grafana-data:/var/lib/grafana      # Grafana 설정 영구 저장
      # [추가] 프로비저닝: InfluxDB 데이터소스를 자동으로 연결
      # ./grafana/provisioning 폴더의 설정이 자동으로 적용됨
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      influxdb:
        condition: service_healthy  # InfluxDB가 준비된 후 시작
    networks:
      - ecommerce-network

  k6:
    # [추가] K6: 부하 테스트 도구
    image: grafana/k6:latest
    container_name: ecommerce-api-k6
    networks:
      - ecommerce-network
    environment:
      # K6 테스트 결과를 InfluxDB로 전송
      - K6_OUT=influxdb=http://influxdb:8086/k6
    volumes:
      # ./k6/scripts 폴더의 테스트 스크립트를 컨테이너에 마운트
      - ./k6/scripts:/scripts
    # [중요] K6를 대기 상태로 유지 (수동 실행용)
    # 테스트는 "docker exec -it ecommerce-api-k6 k6 run /scripts/load-test.js" 로 실행
    command: sleep infinity
    depends_on:
      influxdb:
        condition: service_healthy

networks:
  ecommerce-network:
    driver: bridge   # 도커 기본 네트워크 (같은 네트워크의 컨테이너끼리 통신 가능)

volumes:
  # [추가] Named volumes: 데이터 영구 저장
  # 컨테이너를 삭제해도 데이터는 유지됨
  # "docker-compose down -v" 로 볼륨까지 삭제 가능
  kafka-data:
  mysql-data:
  influxdb-data:
  grafana-data:


# 볼륨 삭제
# docker-compose down -v

# docker-compose up -d


# my-test 토픽의 이전 메시지도 전부 줘
# docker exec -it kafka kafka-console-consumer --topic my-test --bootstrap-server kafka:9092 --from-beginning

# 1. my-test 토픽 생성 (내부 포트 29092 사용)
  #  docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-topics.sh --create --topic my-test --bootstrap-server localhost:29092

  # 2. 메시지 생성 (Producer)
#  docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-console-producer.sh --topic my-test --bootstrap-server localhost:29092

  # 3. 메시지 구독 (Consumer) - 처음부터 다 가져오기
#  docker exec -it ecommerce-api-kafka /opt/kafka/bin/kafka-console-consumer.sh --topic my-test --bootstrap-server localhost:29092 --from-beginning